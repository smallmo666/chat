from langchain_core.messages import AIMessage
from src.workflow.state import AgentState
from src.domain.memory.semantic_cache import get_semantic_cache

def cache_check_node(state: AgentState, config: dict = None) -> dict:
    """
    è¯­ä¹‰ç¼“å­˜æ£€æŸ¥èŠ‚ç‚¹ã€‚
    åœ¨ Planner ä¹‹å‰è¿è¡Œï¼Œå¦‚æœç¼“å­˜å‘½ä¸­ï¼Œç›´æ¥è·³è½¬åˆ° ExecuteSQLã€‚
    """
    print("DEBUG: Entering cache_check_node")
    
    # è·å–ç”¨æˆ·æœ€æ–°æŸ¥è¯¢
    messages = state["messages"]
    last_query = ""
    for msg in reversed(messages):
        if msg.type == "human":
            last_query = msg.content
            break
            
    if not last_query:
        return {"next": "Planner"} # ç»§ç»­å¸¸è§„æµç¨‹

    # è·å– Project ID
    project_id = config.get("configurable", {}).get("project_id") if config else None
    
    # æ£€æŸ¥ç¼“å­˜
    cache = get_semantic_cache(project_id)
    cached_sql = cache.check(last_query)
    
    if cached_sql:
        print(f"DEBUG: Cache Hit! SQL: {cached_sql}")
        return {
            "sql": cached_sql,
            "next": "ExecuteSQL", # è·³è¿‡ä¸­é—´æ­¥éª¤
            # æˆ‘ä»¬éœ€è¦ä¼ªé€ ä¸€ä¸ª Planï¼Œå¦åˆ™ Supervisor å¯èƒ½ä¼šå›°æƒ‘ï¼Œæˆ–è€…æˆ‘ä»¬ç›´æ¥å‘Šè¯‰ Supervisor ä¸‹ä¸€æ­¥
            # ä½†ä¸ºäº† UI æ˜¾ç¤ºï¼Œæˆ‘ä»¬å¯ä»¥æ³¨å…¥ä¸€ä¸ªâ€œè™šæ‹Ÿè®¡åˆ’â€
            "plan": [
                {"node": "CacheCheck", "desc": "è¯­ä¹‰ç¼“å­˜å‘½ä¸­", "status": "completed"},
                {"node": "ExecuteSQL", "desc": "æ‰§è¡Œç¼“å­˜ SQL", "status": "wait"}
            ],
            "current_step_index": 1,
            "messages": [AIMessage(content="ğŸ” å‘ç°ç›¸ä¼¼çš„å†å²æŸ¥è¯¢ï¼Œå·²ä»ç¼“å­˜åŠ è½½ SQLã€‚")]
        }
    
    # Cache Miss
    return {"next": "Planner"}
